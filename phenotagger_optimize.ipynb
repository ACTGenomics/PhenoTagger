{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "PhenoTagger FastAPI Usage Examples\n",
    "Examples showing how to use the FastAPI endpoints\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# API base URL (change this to your server URL)\n",
    "BASE_URL = \"http://192.168.5.77:8111\"\n",
    "\n",
    "def test_health_check():\n",
    "    \"\"\"Test the health check endpoint\"\"\"\n",
    "    print(\"=== Health Check ===\")\n",
    "    \n",
    "    response = requests.get(f\"{BASE_URL}/health\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(f\"Status: {data['status']}\")\n",
    "        print(f\"Model: {data['model_info']}\")\n",
    "        print(\"✓ API is healthy\")\n",
    "    else:\n",
    "        print(f\"✗ Health check failed: {response.status_code}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def batch_annotation(texts, threshold=0.95, only_longest=False, abbr_recognition=True):\n",
    "    \"\"\"Test batch text annotation with large dataset\"\"\"\n",
    "\n",
    "    \n",
    "    data = {\n",
    "        \"texts\": texts,\n",
    "        \"threshold\": threshold,\n",
    "        \"only_longest\": only_longest,\n",
    "        \"abbr_recognition\": abbr_recognition\n",
    "    }\n",
    "    \n",
    "    # Make request\n",
    "    response = requests.post(f\"{BASE_URL}/annotate/batch\", json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"Processed {result['count']} texts in {result['total_processing_time']:.3f}s\")\n",
    "        print(f\"Average time per text: {result['total_processing_time']/result['count']:.3f}s\")\n",
    "        return result\n",
    "    else:\n",
    "        print(f\"✗ Batch annotation failed: {response.status_code}\")\n",
    "        print(response.text)\n",
    "    print()\n",
    "\n",
    "def test_configuration():\n",
    "    \"\"\"Test configuration endpoint\"\"\"\n",
    "    print(\"=== Configuration ===\")\n",
    "    \n",
    "    response = requests.get(f\"{BASE_URL}/config\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        config = response.json()\n",
    "        print(\"Model Info:\")\n",
    "        for key, value in config['model_info'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        print(\"\\nEnvironment:\")\n",
    "        env_info = config['environment']\n",
    "        print(f\"  Model Type: {env_info['processing_params']['model_type']}\")\n",
    "        print(f\"  Threshold: {env_info['processing_params']['ML_Threshold']}\")\n",
    "        print(f\"  Only Longest: {env_info['processing_params']['onlyLongest']}\")\n",
    "        print(\"✓ Configuration retrieved\")\n",
    "    else:\n",
    "        print(f\"✗ Configuration failed: {response.status_code}\")\n",
    "    print()\n",
    "\n",
    "def test_parameter_variations():\n",
    "    \"\"\"Test different parameter combinations\"\"\"\n",
    "    print(\"=== Parameter Variations ===\")\n",
    "    \n",
    "    text = \"The patient has developmental delay, seizures, and intellectual disability.\"\n",
    "    \n",
    "    # Test different parameter combinations\n",
    "    parameter_sets = [\n",
    "        {\"threshold\": 0.95, \"only_longest\": True, \"abbr_recognition\": False},\n",
    "        {\"threshold\": 0.90, \"only_longest\": False, \"abbr_recognition\": True},\n",
    "        {\"threshold\": 0.85, \"only_longest\": True, \"abbr_recognition\": True}\n",
    "    ]\n",
    "    \n",
    "    print(f\"Testing text: {text}\\n\")\n",
    "    \n",
    "    for i, params in enumerate(parameter_sets, 1):\n",
    "        data = {\"text\": text, **params}\n",
    "        response = requests.post(f\"{BASE_URL}/annotate\", json=data)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"Test {i} - Parameters: {params}\")\n",
    "            print(f\"HPO Terms: {result['hpo_terms']}\")\n",
    "            print(f\"HPO IDs: {result['hpo_ids']}\")\n",
    "            print(f\"Time: {result['processing_time']:.3f}s\")\n",
    "        else:\n",
    "            print(f\"Test {i} failed: {response.status_code}\")\n",
    "        print()\n",
    "\n",
    "def test_large_batch():\n",
    "    \"\"\"Test very large batch processing\"\"\"\n",
    "    print(\"=== Large Batch Test ===\")\n",
    "    \n",
    "    # Generate a large number of texts for stress testing\n",
    "    base_texts = [\n",
    "        \"Patient has seizures and developmental delay.\",\n",
    "        \"Clinical findings include intellectual disability.\",\n",
    "        \"Neurological examination shows tremor and ataxia.\",\n",
    "        \"The child exhibits growth retardation.\",\n",
    "        \"Patient presents with microcephaly and motor delays.\"\n",
    "    ]\n",
    "    \n",
    "    # Create a batch of 500 texts\n",
    "    large_batch = base_texts * 100  # 500 texts\n",
    "    \n",
    "    print(f\"Testing with {len(large_batch)} texts...\")\n",
    "    \n",
    "    data = {\n",
    "        \"texts\": large_batch,\n",
    "        \"threshold\": 0.95,\n",
    "        \"only_longest\": True\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = requests.post(f\"{BASE_URL}/annotate/batch\", json=data)\n",
    "    request_time = time.time() - start_time\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"✓ Successfully processed {result['count']} texts\")\n",
    "        print(f\"Server processing time: {result['total_processing_time']:.3f}s\")\n",
    "        print(f\"Total request time: {request_time:.3f}s\")\n",
    "        print(f\"Average time per text: {result['total_processing_time']/result['count']:.4f}s\")\n",
    "        \n",
    "        # Show sample results\n",
    "        print(\"\\nSample results:\")\n",
    "        for i, annotation in enumerate(result['results'][:2], 1):\n",
    "            print(f\"{i}. Text: {annotation['text']}\")\n",
    "            print(f\"   HPO IDs: {annotation['hpo_ids']}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"✗ Large batch test failed: {response.status_code}\")\n",
    "        print(response.text)\n",
    "    print()\n",
    "\n",
    "def test_error_handling():\n",
    "    \"\"\"Test error handling\"\"\"\n",
    "    print(\"=== Error Handling ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Configuration ===\n",
      "Model Info:\n",
      "  model_type: pubmedbert\n",
      "  threshold: 0.95\n",
      "  only_longest: False\n",
      "  abbr_recognition: True\n",
      "  api_version: 2.0\n",
      "\n",
      "Environment:\n",
      "  Model Type: pubmedbert\n",
      "  Threshold: 0.95\n",
      "  Only Longest: False\n",
      "✓ Configuration retrieved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始DataFrame:\n",
      "  patient_id                          true_hpo  \\\n",
      "0       P001  HP:0001250;HP:0002376;HP:0001263   \n",
      "1       P002             HP:0001250;HP:0003674   \n",
      "2       P003  HP:0002376;HP:0001263;HP:0004944   \n",
      "3       P004                        HP:0001250   \n",
      "4       P005             HP:0003674;HP:0004944   \n",
      "\n",
      "                           pred_hpo  \n",
      "0  HP:0001250;HP:0001263;HP:0003674  \n",
      "1             HP:0001250;HP:0002376  \n",
      "2             HP:0002376;HP:0001263  \n",
      "3             HP:0001250;HP:0004944  \n",
      "4                        HP:0003674  \n",
      "\n",
      "================================================================================\n",
      "資料集中共有 5 個不同的真實HPO\n",
      "\n",
      "添加評估指標後的DataFrame:\n",
      "  patient_id  TP  FP  TN  FN  precision  recall  f1_score\n",
      "0       P001   2   1   1   1      0.667   0.667     0.667\n",
      "1       P002   1   1   2   1      0.500   0.500     0.500\n",
      "2       P003   2   0   2   1      1.000   0.667     0.800\n",
      "3       P004   1   1   3   0      0.500   1.000     0.667\n",
      "4       P005   1   0   3   1      1.000   0.500     0.667\n",
      "\n",
      "================================================================================\n",
      "整體評估指標:\n",
      "================================================================================\n",
      "總樣本數: 5\n",
      "總TP: 7, 總FP: 3\n",
      "總TN: 11, 總FN: 4\n",
      "\n",
      "【Micro-average 指標】(全局計算)\n",
      "Micro Precision: 0.700\n",
      "Micro Recall: 0.636\n",
      "Micro F1-Score: 0.667\n",
      "Micro Accuracy: 0.720\n",
      "\n",
      "【Macro-average 指標】(論文使用的方法)\n",
      "Macro Precision: 0.733\n",
      "Macro Recall: 0.667\n",
      "Macro F1-Score: 0.660\n",
      "Macro Accuracy: 0.720\n",
      "\n",
      "※ 論文中的結果應該對比 Macro-average 指標\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_hpo_evaluation_metrics(df, true_hpo_col, predict_hpo_col):\n",
    "    \"\"\"\n",
    "    為DataFrame添加HPO評估指標欄位\n",
    "    \n",
    "    Args:\n",
    "        df: 輸入DataFrame\n",
    "        true_hpo_col: 真實HPO欄位名稱 (字串格式，用';'分隔)\n",
    "        predict_hpo_col: 預測HPO欄位名稱 (字串格式，用';'分隔)\n",
    "        \n",
    "    Returns:\n",
    "        df: 添加了TP, FP, TN, FN, precision, recall, f1_score欄位的DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # 複製DataFrame避免修改原始資料\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # 收集所有真實HPO作為完整集合 (用於計算TN)\n",
    "    all_true_hpos = set()\n",
    "    for hpo_str in result_df[true_hpo_col].dropna():\n",
    "        if hpo_str:  # 檢查非空字串\n",
    "            all_true_hpos.update(hpo_str.split(';'))\n",
    "    \n",
    "    print(f\"資料集中共有 {len(all_true_hpos)} 個不同的真實HPO\")\n",
    "    \n",
    "    # 初始化新欄位\n",
    "    result_df['TP'] = 0\n",
    "    result_df['FP'] = 0\n",
    "    result_df['TN'] = 0\n",
    "    result_df['FN'] = 0\n",
    "    result_df['precision'] = 0.0\n",
    "    result_df['recall'] = 0.0\n",
    "    result_df['f1_score'] = 0.0\n",
    "    \n",
    "    # 逐行計算評估指標\n",
    "    for idx, row in result_df.iterrows():\n",
    "        # 解析HPO集合\n",
    "        true_hpos = set(row[true_hpo_col].split(';')) if pd.notna(row[true_hpo_col]) and row[true_hpo_col] else set()\n",
    "        pred_hpos = set(row[predict_hpo_col].split(';')) if pd.notna(row[predict_hpo_col]) and row[predict_hpo_col] else set()\n",
    "        \n",
    "        # 計算混淆矩陣\n",
    "        tp = len(true_hpos & pred_hpos)  # 交集：預測正確的\n",
    "        fp = len(pred_hpos - true_hpos)  # 預測有但真實沒有\n",
    "        fn = len(true_hpos - pred_hpos)  # 真實有但預測沒有\n",
    "        tn = len(all_true_hpos - true_hpos - pred_hpos)  # 資料集中存在但此樣本都沒有\n",
    "        \n",
    "        # 計算評估指標\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        # 更新DataFrame\n",
    "        result_df.loc[idx, 'TP'] = tp\n",
    "        result_df.loc[idx, 'FP'] = fp\n",
    "        result_df.loc[idx, 'TN'] = tn\n",
    "        result_df.loc[idx, 'FN'] = fn\n",
    "        result_df.loc[idx, 'precision'] = precision\n",
    "        result_df.loc[idx, 'recall'] = recall\n",
    "        result_df.loc[idx, 'f1_score'] = f1_score\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def get_overall_metrics(df):\n",
    "    \"\"\"\n",
    "    計算整體評估指標 (包含 Micro-average 和 Macro-average)\n",
    "    \n",
    "    Args:\n",
    "        df: 包含TP, FP, TN, FN欄位的DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        dict: 整體評估指標\n",
    "    \"\"\"\n",
    "    \n",
    "    total_tp = df['TP'].sum()\n",
    "    total_fp = df['FP'].sum()\n",
    "    total_tn = df['TN'].sum()\n",
    "    total_fn = df['FN'].sum()\n",
    "    \n",
    "    # Micro-average 指標 (全局加總後計算)\n",
    "    micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    micro_f1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0.0\n",
    "    micro_accuracy = (total_tp + total_tn) / (total_tp + total_fp + total_tn + total_fn) if (total_tp + total_fp + total_tn + total_fn) > 0 else 0.0\n",
    "    \n",
    "    # Macro-average 指標 (每個樣本指標的平均，論文使用的方法)\n",
    "    macro_precision = df['precision'].mean()\n",
    "    macro_recall = df['recall'].mean()\n",
    "    macro_f1 = df['f1_score'].mean()\n",
    "    macro_accuracy = ((df['TP'] + df['TN']) / (df['TP'] + df['FP'] + df['TN'] + df['FN'])).mean()\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df),\n",
    "        'total_TP': total_tp,\n",
    "        'total_FP': total_fp,\n",
    "        'total_TN': total_tn,\n",
    "        'total_FN': total_fn,\n",
    "        \n",
    "        # Micro-average (全局指標)\n",
    "        'micro_precision': micro_precision,\n",
    "        'micro_recall': micro_recall,\n",
    "        'micro_f1_score': micro_f1,\n",
    "        'micro_accuracy': micro_accuracy,\n",
    "        \n",
    "        # Macro-average (論文使用的方法)\n",
    "        'macro_precision': macro_precision,\n",
    "        'macro_recall': macro_recall,\n",
    "        'macro_f1_score': macro_f1,\n",
    "        'macro_accuracy': macro_accuracy,\n",
    "        \n",
    "        # 為了向後兼容保留舊名稱\n",
    "        'overall_precision': micro_precision,\n",
    "        'overall_recall': micro_recall,\n",
    "        'overall_f1_score': micro_f1,\n",
    "        'overall_accuracy': micro_accuracy,\n",
    "        'avg_precision': macro_precision,\n",
    "        'avg_recall': macro_recall,\n",
    "        'avg_f1_score': macro_f1\n",
    "    }\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 創建示例DataFrame\n",
    "    sample_data = {\n",
    "        'patient_id': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
    "        'true_hpo': [\n",
    "            'HP:0001250;HP:0002376;HP:0001263',\n",
    "            'HP:0001250;HP:0003674',\n",
    "            'HP:0002376;HP:0001263;HP:0004944',\n",
    "            'HP:0001250',\n",
    "            'HP:0003674;HP:0004944'\n",
    "        ],\n",
    "        'pred_hpo': [\n",
    "            'HP:0001250;HP:0001263;HP:0003674',\n",
    "            'HP:0001250;HP:0002376',\n",
    "            'HP:0002376;HP:0001263',\n",
    "            'HP:0001250;HP:0004944',\n",
    "            'HP:0003674'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    print(\"原始DataFrame:\")\n",
    "    print(df)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # 添加評估指標\n",
    "    result_df = add_hpo_evaluation_metrics(df, 'true_hpo', 'pred_hpo')\n",
    "    \n",
    "    print(\"\\n添加評估指標後的DataFrame:\")\n",
    "    print(result_df[['patient_id', 'TP', 'FP', 'TN', 'FN', 'precision', 'recall', 'f1_score']].round(3))\n",
    "    \n",
    "    # 計算整體指標\n",
    "    overall = get_overall_metrics(result_df)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"整體評估指標:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"總樣本數: {overall['total_samples']}\")\n",
    "    print(f\"總TP: {overall['total_TP']}, 總FP: {overall['total_FP']}\")\n",
    "    print(f\"總TN: {overall['total_TN']}, 總FN: {overall['total_FN']}\")\n",
    "    \n",
    "    print(\"\\n【Micro-average 指標】(全局計算)\")\n",
    "    print(f\"Micro Precision(TP / TP+FP): {overall['micro_precision']:.3f}\")\n",
    "    print(f\"Micro Recall: {overall['micro_recall']:.3f}\")\n",
    "    print(f\"Micro F1-Score: {overall['micro_f1_score']:.3f}\")\n",
    "    print(f\"Micro Accuracy: {overall['micro_accuracy']:.3f}\")\n",
    "    \n",
    "    print(\"\\n【Macro-average 指標】(論文使用的方法)\")\n",
    "    print(f\"Macro Precision: {overall['macro_precision']:.3f}\")\n",
    "    print(f\"Macro Recall: {overall['macro_recall']:.3f}\")\n",
    "    print(f\"Macro F1-Score: {overall['macro_f1_score']:.3f}\")\n",
    "    print(f\"Macro Accuracy: {overall['macro_accuracy']:.3f}\")\n",
    "    \n",
    "    print(\"\\n※ 論文中的結果應該對比 Macro-average 指標\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpo_reformat(x):\n",
    "    if x == '-':\n",
    "        return x\n",
    "    hpo_list = x.split(';')\n",
    "    return ';'.join(hpo.replace('_',':') for hpo in hpo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "biolarkgsc = pd.read_csv('../PhenoBERT/reference/HPO concept recognition/BiolarkGSC/biolarkgsc.csv', sep='\\t')\n",
    "# cpod = pd.read_csv('../PhenoBERT/reference/HPO concept recognition/COPD-HPO/copd.csv',sep='\\t')\n",
    "# phenochf = pd.read_csv('../PhenoBERT/reference/HPO concept recognition/PhenoCHF/phenochf.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "biolarkgsc['dataset'] = 'biolarkgsc'\n",
    "# phenochf['dataset'] = 'phenochf'\n",
    "# cpod['dataset'] = 'copd'\n",
    "\n",
    "#total_dataset = pd.concat([biolarkgsc, cpod, phenochf], ignore_index=True)\n",
    "biolarkgsc['labels'] = biolarkgsc['labels'].fillna('-')\n",
    "biolarkgsc['hpo_ids'] = biolarkgsc['labels'].apply(hpo_reformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biolarkgsc = biolarkgsc.rename(columns={'text':'clinical_summary'})\n",
    "biolarkgsc['clinical_summary'] = biolarkgsc['clinical_summary'].fillna('-')\n",
    "biolarkgsc = biolarkgsc[['id','clinical_summary','hpo_ids','dataset']]\n",
    "biolarkgsc = biolarkgsc[(biolarkgsc['clinical_summary'] !='-') & (biolarkgsc['hpo_ids'] != '-')]\n",
    "biolarkgsc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpo_mapping = pd.read_csv('../PhenoBERT/reference/2025-08-01_orphanet_WGS_database(HPO_ID_Mapping_v20250506).csv', sep=',')\n",
    "\n",
    "hpo_mapping_dict = {}\n",
    "for idx in df_hpo_mapping.index:\n",
    "    hpo_mapping_dict[df_hpo_mapping.input_hpo_id[idx]] = df_hpo_mapping.mapped_main_id[idx]\n",
    "\n",
    "def hpo_map(hpo_id_list_str):\n",
    "    if hpo_id_list_str =='-':\n",
    "        return '-'\n",
    "    hpo_id_list = hpo_id_list_str.split(';')\n",
    "    normalized_hpo_id_list = []\n",
    "    for hpo_id in hpo_idwwww_list:\n",
    "        if hpo_id not in normalized_hpo_id_list:\n",
    "            normalized_hpo_id_list.append(hpo_mapping_dict.get(hpo_id,'-'))\n",
    "    return ';'.join(normalized_hpo_id_list)\n",
    "\n",
    "def accuracy_calculator(true_hpo_str, pred_hpo_str):\n",
    "    true_hpo_list = true_hpo_str.split(';')\n",
    "    pred_hpo_list = pred_hpo_str.split(';')\n",
    "    mapped_hpo_list = [hpo for hpo in pred_hpo_list if hpo in true_hpo_list]\n",
    "    return len(mapped_hpo_list)/len(true_hpo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:bioformer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 228 texts in 68.937s\n",
      "Average time per text: 0.302s\n"
     ]
    }
   ],
   "source": [
    "print('model:bioformer')\n",
    "pheno_tagger_output = batch_annotation(\n",
    "    biolarkgsc['clinical_summary'].to_list(),\n",
    "    threshold=0.95, only_longest=True, abbr_recognition=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_tagger_hpo_ids = [data['hpo_ids'] for data in pheno_tagger_output['results']]\n",
    "biolarkgsc['pheno_tagger_hpo_ids'] = pheno_tagger_hpo_ids\n",
    "biolarkgsc['normalized_hpo_ids'] = biolarkgsc['hpo_ids'].apply(hpo_map)\n",
    "biolarkgsc['normalized_pheno_tagger_hpo_ids'] = biolarkgsc['pheno_tagger_hpo_ids'].apply(hpo_map)\n",
    "biolarkgsc['pheno_tagger_accuracy'] = biolarkgsc.apply(lambda x:accuracy_calculator(x.normalized_hpo_ids, x.normalized_pheno_tagger_hpo_ids), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料集中共有 461 個不同的真實HPO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "整體評估指標:\n",
      "================================================================================\n",
      "總樣本數: 228\n",
      "總TP: 852, 總FP: 203\n",
      "總TN: 103342, 總FN: 855\n",
      "\n",
      "【Micro-average 指標】(全局計算)\n",
      "Micro Precision (TP/TP+FP): 0.808\n",
      "Micro Recall (TP/TP+FN): 0.499\n",
      "Micro F1-Score (2 * Recall * Precision / (Recall+Precision)): 0.617\n",
      "Micro Accuracy: 0.990\n",
      "\n",
      "【Macro-average 指標】(論文使用的方法)\n",
      "Macro Precision (TP/TP+FP): 0.775\n",
      "Macro Recall (TP/TP+FN): 0.503\n",
      "Macro F1-Score (2 * Recall * Precision / (Recall+Precision)): 0.590\n",
      "Macro Accuracy: 0.990\n",
      "\n",
      "※ 論文中的結果應該對比 Macro-average 指標\n"
     ]
    }
   ],
   "source": [
    "biolarkgsc = add_hpo_evaluation_metrics(biolarkgsc,'normalized_hpo_ids','normalized_pheno_tagger_hpo_ids')\n",
    "overall = get_overall_metrics(biolarkgsc)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"整體評估指標:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"總樣本數: {overall['total_samples']}\")\n",
    "print(f\"總TP: {overall['total_TP']}, 總FP: {overall['total_FP']}\")\n",
    "print(f\"總TN: {overall['total_TN']}, 總FN: {overall['total_FN']}\")\n",
    "\n",
    "print(\"\\n【Micro-average 指標】(全局計算)\")\n",
    "print(f\"Micro Precision (TP/TP+FP): {overall['micro_precision']:.3f}\")\n",
    "print(f\"Micro Recall (TP/TP+FN): {overall['micro_recall']:.3f}\")\n",
    "print(f\"Micro F1-Score (2 * Recall * Precision / (Recall+Precision)): {overall['micro_f1_score']:.3f}\")\n",
    "print(f\"Micro Accuracy: {overall['micro_accuracy']:.3f}\")\n",
    "\n",
    "print(\"\\n【Macro-average 指標】(論文使用的方法)\")\n",
    "print(f\"Macro Precision (TP/TP+FP): {overall['macro_precision']:.3f}\")\n",
    "print(f\"Macro Recall (TP/TP+FN): {overall['macro_recall']:.3f}\")\n",
    "print(f\"Macro F1-Score (2 * Recall * Precision / (Recall+Precision)): {overall['macro_f1_score']:.3f}\")\n",
    "print(f\"Macro Accuracy: {overall['macro_accuracy']:.3f}\")\n",
    "\n",
    "print(\"\\n※ 論文中的結果應該對比 Macro-average 指標\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5837626325546885"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biolarkgsc['pheno_tagger_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biolarkgsc['pheno_tagger_accuracy'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clinical_summary</th>\n",
       "      <th>hpo_ids</th>\n",
       "      <th>dataset</th>\n",
       "      <th>pheno_tagger_hpo_ids</th>\n",
       "      <th>normalized_hpo_ids</th>\n",
       "      <th>normalized_pheno_tagger_hpo_ids</th>\n",
       "      <th>pheno_tagger_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003450</td>\n",
       "      <td>A syndrome of brachydactyly (absence of some m...</td>\n",
       "      <td>HP:0001156;HP:0009881;HP:0001798;HP:0001792;HP...</td>\n",
       "      <td>biolarkgsc</td>\n",
       "      <td>HP:0001156;HP:0008386;HP:0001792;HP:0006152;HP...</td>\n",
       "      <td>HP:0001156;HP:0009881;HP:0001798;HP:0001792;HP...</td>\n",
       "      <td>HP:0001156;HP:0008386;HP:0001792;HP:0006152;HP...</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10051003</td>\n",
       "      <td>Townes-Brocks syndrome (TBS) is an autosomal d...</td>\n",
       "      <td>HP:0000006;HP:0000006;HP:0000006;HP:0003828;HP...</td>\n",
       "      <td>biolarkgsc</td>\n",
       "      <td>HP:0000356;HP:0000365;HP:0100258;HP:0010442;HP...</td>\n",
       "      <td>HP:0000006;HP:0003828;HP:0003812;HP:0000356;HP...</td>\n",
       "      <td>HP:0000356;HP:0000365;HP:0100258;HP:0010442;HP...</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10066029</td>\n",
       "      <td>Nevoid basal cell carcinoma syndrome (NBCCS) i...</td>\n",
       "      <td>HP:0002671;HP:0000006;HP:0000006;HP:0000006;HP...</td>\n",
       "      <td>biolarkgsc</td>\n",
       "      <td>HP:0002671;HP:0030731;HP:0002671;HP:0030731;HP...</td>\n",
       "      <td>HP:0002671;HP:0000006;HP:0003828;HP:0003812;HP...</td>\n",
       "      <td>HP:0002671;HP:0030731;HP:0010603;HP:0010610;HP...</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10196695</td>\n",
       "      <td>Angelman syndrome (AS) is a neurodevelopmental...</td>\n",
       "      <td>HP:0000707;HP:0001466</td>\n",
       "      <td>biolarkgsc</td>\n",
       "      <td>HP:0012759;HP:0030868;HP:0030868</td>\n",
       "      <td>HP:0000707;HP:0001466</td>\n",
       "      <td>HP:0012759;HP:0030868</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10417280</td>\n",
       "      <td>Prader-Willi syndrome (PWS) and Angelman syndr...</td>\n",
       "      <td>HP:0000708;HP:0003745</td>\n",
       "      <td>biolarkgsc</td>\n",
       "      <td>HP:0012452;HP:0000708</td>\n",
       "      <td>HP:0000708;HP:0003745</td>\n",
       "      <td>HP:0012452;HP:0000708</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                   clinical_summary  \\\n",
       "0   1003450  A syndrome of brachydactyly (absence of some m...   \n",
       "1  10051003  Townes-Brocks syndrome (TBS) is an autosomal d...   \n",
       "2  10066029  Nevoid basal cell carcinoma syndrome (NBCCS) i...   \n",
       "3  10196695  Angelman syndrome (AS) is a neurodevelopmental...   \n",
       "4  10417280  Prader-Willi syndrome (PWS) and Angelman syndr...   \n",
       "\n",
       "                                             hpo_ids     dataset  \\\n",
       "0  HP:0001156;HP:0009881;HP:0001798;HP:0001792;HP...  biolarkgsc   \n",
       "1  HP:0000006;HP:0000006;HP:0000006;HP:0003828;HP...  biolarkgsc   \n",
       "2  HP:0002671;HP:0000006;HP:0000006;HP:0000006;HP...  biolarkgsc   \n",
       "3                              HP:0000707;HP:0001466  biolarkgsc   \n",
       "4                              HP:0000708;HP:0003745  biolarkgsc   \n",
       "\n",
       "                                pheno_tagger_hpo_ids  \\\n",
       "0  HP:0001156;HP:0008386;HP:0001792;HP:0006152;HP...   \n",
       "1  HP:0000356;HP:0000365;HP:0100258;HP:0010442;HP...   \n",
       "2  HP:0002671;HP:0030731;HP:0002671;HP:0030731;HP...   \n",
       "3                   HP:0012759;HP:0030868;HP:0030868   \n",
       "4                              HP:0012452;HP:0000708   \n",
       "\n",
       "                                  normalized_hpo_ids  \\\n",
       "0  HP:0001156;HP:0009881;HP:0001798;HP:0001792;HP...   \n",
       "1  HP:0000006;HP:0003828;HP:0003812;HP:0000356;HP...   \n",
       "2  HP:0002671;HP:0000006;HP:0003828;HP:0003812;HP...   \n",
       "3                              HP:0000707;HP:0001466   \n",
       "4                              HP:0000708;HP:0003745   \n",
       "\n",
       "                     normalized_pheno_tagger_hpo_ids  pheno_tagger_accuracy  \n",
       "0  HP:0001156;HP:0008386;HP:0001792;HP:0006152;HP...               0.400000  \n",
       "1  HP:0000356;HP:0000365;HP:0100258;HP:0010442;HP...               0.583333  \n",
       "2  HP:0002671;HP:0030731;HP:0010603;HP:0010610;HP...               0.636364  \n",
       "3                              HP:0012759;HP:0030868               0.000000  \n",
       "4                              HP:0012452;HP:0000708               0.500000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biolarkgsc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pheno-tagger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
